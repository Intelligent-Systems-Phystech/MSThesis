{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append('./source/')\n",
    "\n",
    "from data_processing import *\n",
    "from feature_extraction import *\n",
    "from scoring import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_uschad = pd.read_table(\"../data/USC-HAD/USC-HAD_cleared.txt\", delimiter=',', header=None)\n",
    "data_uschad.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']\n",
    "\n",
    "data_wisdm = pd.read_table(\"../data/WISDM/WISDM_ar_v1.1_raw_cleared.txt\", delimiter=',', header=None)\n",
    "data_wisdm.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is the following: we will consider 10 seconds time series (or 200 points of measurements) and calculate 40 features:\n",
    "* ```[3]``` - mean acceleration of each axis;\n",
    "* ```[3]``` - std of acceleration of each axis;\n",
    "* ```[3]``` - mean absolute deviation of acceleration of each axis;\n",
    "* ```[1]``` - mean acceleration;\n",
    "* ```[30]``` - distribution of time series values of each axis. First of all we calculate min and max of each component ($X, Y, Z$) from the whole interval. Then we divide the range of values of each component into 10 equal intervals and calculate on each each interval the percent of values that are in it (in the corresponding interval).  \n",
    "\n",
    "And apply LogisticRegression, SVM and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standing            229      5.30  %\n",
      "Walking             1917     44.36 %\n",
      "Upstairs            466      10.78 %\n",
      "Sitting             277      6.41  %\n",
      "Jogging             1075     24.88 %\n",
      "Downstairs          357      8.26  %\n",
      "\n",
      "Number of objects: 4321\n"
     ]
    }
   ],
   "source": [
    "df_expert_wisdm = get_feature_matrix(data_wisdm, 'WISDM', \n",
    "                                     get_expert_names, get_expert_features)\n",
    "get_distribution(data_wisdm, df_expert_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_expert_uschad = get_feature_matrix(data_uschad, 'USCHAD', \n",
    "                                      get_expert_names, get_expert_features)\n",
    "get_distribution(data_uschad, df_expert_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = list(10)\n",
    "n = params[0]\n",
    "\n",
    "df_ar_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_autoregressive_names,\n",
    "                                 get_autoregressive_features, params)\n",
    "get_distribution(data_wisdm, df_ar_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ar_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_autoregressive_names,\n",
    "                                  get_autoregressive_features, params)\n",
    "get_distribution(data_uschad, df_ar_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = list(10)\n",
    "n = params[0]\n",
    "\n",
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spectrum_names,\n",
    "                                  get_spectrum_features, params)\n",
    "get_distribution(data_wisdm, df_ssa_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spectrum_names,\n",
    "                                   get_spectrum_features, params)\n",
    "get_distribution(data_uschad, df_ssa_uschad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['l1', 'l2'], \n",
    "              'class_weight': ['balanced', None], \n",
    "              'C': 10. ** np.arange(0, 4, 1)}\n",
    "\n",
    "scores_wisdm = {}\n",
    "scores_uschad = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expert** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_expert'] = get_score(df_expert_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_expert'] = get_score(df_expert_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **autoregression model** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_ar_' + str(n)] = get_score(df_ar_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_ar_' + str(n)] = get_score(df_ar_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **spectrum analysis** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_wisdm['lr_ssa_' + str(n)] = get_score(df_ssa_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['lr_ssa_' + str(n)] = get_score(df_ssa_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **splines** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_wisdm['splines' + str(n)] = get_score(df_ssa_wisdm, LogisticRegression(), parameters)\n",
    "scores_uschad['splines' + str(n)] = get_score(df_ssa_uschad, LogisticRegression(), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_wisdm = pd.DataFrame.from_dict(scores_wisdm, orient='index')\n",
    "results_wisdm.columns = ['all'] + list(set(data_wisdm['activity']))\n",
    "\n",
    "results_uschad = pd.DataFrame.from_dict(scores_uschad, orient='index')\n",
    "results_uschad.columns = ['all'] + list(set(data_uschad['activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_wisdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_uschad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
