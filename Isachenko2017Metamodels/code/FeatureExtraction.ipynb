{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.interpolate import splrep, splev, splprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_uschad = pd.read_table(\"../data/USC-HAD/USC-HAD_cleared.txt\", delimiter=',', header=None)\n",
    "data_uschad.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']\n",
    "\n",
    "data_wisdm = pd.read_table(\"../data/WISDM/WISDM_ar_v1.1_raw_cleared.txt\", delimiter=',', header=None)\n",
    "data_wisdm.columns = ['id_user', 'activity', 'timestamp', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to construct 10 seconds time series. To do it we need to remember the following:\n",
    "* each time series should be from one user and one type of activity;\n",
    "* in the time series timestamp should't differ more then 0.2 second (empirical rule, in ideal all timestamp should differ on 50 ms = 0.05 second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create **object-feature** matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_candidate(candidate, data_type, threshold=2.*1e8):\n",
    "    if data_type == \"USCHAD\":\n",
    "        threshold = 0.\n",
    "    tsp = np.array(candidate['timestamp'])\n",
    "    diffs = tsp[1:] - tsp[:-1]\n",
    "    \n",
    "    return np.sum(diffs > threshold) == 0\n",
    "\n",
    "def get_time_series(accelerations, data_type, nb=200):\n",
    "    accelerations.index = [i for i in range(len(accelerations))]\n",
    "    TS = []\n",
    "    st = 0\n",
    "    fi = st + nb\n",
    "    while fi < len(accelerations):\n",
    "        candidate = accelerations.loc[[st + i for i in range(nb)], :]\n",
    "        if check_candidate(candidate, data_type):\n",
    "            TS.append([np.array(candidate['x']), \n",
    "                       np.array(candidate['y']), \n",
    "                       np.array(candidate['z'])])\n",
    "        st = fi\n",
    "        fi += nb\n",
    "    \n",
    "    return TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distribution(data, df):\n",
    "    classes = list(set(data['activity']))\n",
    "    for activity in classes:\n",
    "        nb = np.sum(df['activity'] == classes.index(activity))\n",
    "        print(\"{:<20}{:<9d}{:<5.2f} %\".format(activity, nb, 100. * nb / df.shape[0]))\n",
    "    print(\"\")\n",
    "    print(\"Number of objects: {:d}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(data, data_type, get_feature_names, get_features, params=[]):\n",
    "    \n",
    "    classes = list(set(data['activity']))\n",
    "    feature_names = get_feature_names(params)\n",
    "    df = pd.DataFrame(columns=['activity']+feature_names) \n",
    "\n",
    "    id_range = np.unique(np.array(data['id_user']))\n",
    "    for id_user in id_range:\n",
    "        for activity in classes:\n",
    "            mask = (data.loc[:, 'id_user'] == id_user) & (data.loc[:, 'activity'] == activity)\n",
    "            accelerations = data.loc[mask, ['timestamp', 'x', 'y', 'z']].copy()\n",
    "            TS = get_time_series(accelerations, data_type, nb=200)\n",
    "            for ts in TS:\n",
    "                features = get_features(ts, params)\n",
    "                df.loc[len(df), :] = [classes.index(activity)] + features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is the following: we will consider 10 seconds time series (or 200 points of measurements) and calculate 40 features:\n",
    "* ```[3]``` - mean acceleration of each axis;\n",
    "* ```[3]``` - std of acceleration of each axis;\n",
    "* ```[3]``` - mean absolute deviation of acceleration of each axis;\n",
    "* ```[1]``` - mean acceleration;\n",
    "* ```[30]``` - distribution of time series values of each axis. First of all we calculate min and max of each component ($X, Y, Z$) from the whole interval. Then we divide the range of values of each component into 10 equal intervals and calculate on each each interval the percent of values that are in it (in the corresponding interval).  \n",
    "\n",
    "And apply LogisticRegression and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expert_names(params):\n",
    "    feature_names = ['avg_x', 'avg_y', 'avg_z', \n",
    "                     'std_x', 'std_y', 'std_z', \n",
    "                     'abs_x', 'abs_y', 'abs_z', 'mean']\n",
    "    for i in range(10):\n",
    "        name = str(i) + '_'\n",
    "        feature_names += [name + 'x', name + 'y', name + 'z']\n",
    "        \n",
    "    return feature_names\n",
    "\n",
    "def get_expert_features(ts, params):\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    n = x.shape[0]\n",
    "    features = []\n",
    "    features.append(x.mean())\n",
    "    features.append(y.mean())\n",
    "    features.append(z.mean())\n",
    "    features.append(x.std())\n",
    "    features.append(y.std())\n",
    "    features.append(z.std())\n",
    "    features.append(np.abs(x - x.mean()).mean())\n",
    "    features.append(np.abs(y - y.mean()).mean())\n",
    "    features.append(np.abs(z - z.mean()).mean())\n",
    "    features.append((x+y+z).mean() / 3.)\n",
    "    x_range = np.linspace(x.min(), x.max(), 11)\n",
    "    y_range = np.linspace(y.min(), y.max(), 11)\n",
    "    z_range = np.linspace(z.min(), z.max(), 11)\n",
    "    for i in range(10):\n",
    "        features.append(1. * np.sum((x_range[i] <= x) & (x < x_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((y_range[i] <= y) & (y < y_range[i+1])) / n)\n",
    "        features.append(1. * np.sum((z_range[i] <= z) & (z < z_range[i+1])) / n)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_expert_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_expert_names, get_expert_features)\n",
    "df_expert_wisdm.to_csv(\"../data/features/expert_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_expert_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_expert_names, get_expert_features)\n",
    "df_expert_uschad.to_csv(\"../data/features/expert_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_autoregressive_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        feature_names += ['intercept_' + ax]\n",
    "        for i in range(n):\n",
    "            feature_names += ['coef_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_autoregressive_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "            Y[i] = axis[i+n]\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, Y)\n",
    "        features.append(lr.intercept_)\n",
    "        features.extend(lr.coef_)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ar_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_autoregressive_names,\n",
    "                                 get_autoregressive_features, params)\n",
    "df_ar_wisdm.to_csv(\"../data/features/ar_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ar_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_autoregressive_names,\n",
    "                                  get_autoregressive_features, params)\n",
    "df_ar_uschad.to_csv(\"../data/features/ar_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrum_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        for i in range(n):\n",
    "            feature_names += ['eigv_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_spectrum_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    X = np.zeros([m-n, n])\n",
    "    Y = np.zeros(m-n)\n",
    "    for axis in [x, y, z]:\n",
    "        for i in range(m-n):\n",
    "            X[i, :] = axis[i:i+n]\n",
    "        h = sc.linalg.svd(X.T.dot(X), compute_uv=False, overwrite_a=True)\n",
    "        features.extend(h)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spectrum_names,\n",
    "                                  get_spectrum_features, params)\n",
    "df_ssa_wisdm.to_csv(\"../data/features/ssa_wisdm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [20]\n",
    "df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spectrum_names,\n",
    "                                   get_spectrum_features, params)\n",
    "df_ssa_uschad.to_csv(\"../data/features/ssa_uschad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spline_names(params):\n",
    "    n = params[0]\n",
    "    feature_names = []\n",
    "    for ax in ['x', 'y', 'z']:\n",
    "        for i in range(n):\n",
    "            feature_names += ['coef_' + str(i) + '_' + ax]\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "def get_spline(t, ts, n):\n",
    "    s_down = 1e-6\n",
    "    s_up = 1000.\n",
    "    spl = splrep(t, ts, s=s_up)\n",
    "    while len(spl[1]) >= n:\n",
    "        spl = splrep(t, ts, s=s_up)\n",
    "        s_up *= 2.\n",
    "    max_iter = int(np.floor(np.log2(s_up * 1e4)))\n",
    "    num_iter = 0\n",
    "    while (len(spl[1]) != n) and (num_iter <= max_iter):\n",
    "        s = (s_up + s_down) / 2.\n",
    "        spl = splrep(t, ts, s=s)\n",
    "        if len(spl[1]) < n:\n",
    "            s_up = s\n",
    "        else:\n",
    "            s_down = s\n",
    "        num_iter += 1\n",
    "        if num_iter > max_iter:\n",
    "            spl = splrep(t, ts, s=s_down)\n",
    "            \n",
    "    return spl[1][:n]\n",
    "\n",
    "def get_spline_features(ts, params):\n",
    "    n = params[0]\n",
    "    x = ts[0]\n",
    "    y = ts[1]\n",
    "    z = ts[2]\n",
    "    m = x.shape[0]\n",
    "    features = []\n",
    "    t = np.arange(0, m, 1)\n",
    "    spl_x = get_spline(t, x, n)\n",
    "    spl_y = get_spline(t, y, n)\n",
    "    spl_z = get_spline(t, z, n)\n",
    "    features = list(np.concatenate((spl_x, spl_y, spl_z), axis=0))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya\\Anaconda2\\lib\\site-packages\\scipy\\interpolate\\fitpack.py:512: RuntimeWarning: The maximal number of iterations (20) allowed for finding smoothing\n",
      "spline with fp=s has been reached. Probable cause: s too small.\n",
      "(abs(fp-s)/s>0.001)\n",
      "  warnings.warn(RuntimeWarning(_iermess[ier][0]))\n"
     ]
    }
   ],
   "source": [
    "params = [11]\n",
    "df_ssa_wisdm = get_feature_matrix(data_wisdm, 'WISDM', get_spline_names,\n",
    "                                      get_spline_features, params)\n",
    "df_ssa_wisdm.to_csv(\"../data/features/spl_wisdm_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [11]\n",
    "df_ssa_uschad = get_feature_matrix(data_uschad, 'USCHAD', get_spline_names,\n",
    "                                   get_spline_features, params)\n",
    "df_ssa_uschad.to_csv(\"../data/features/spl_uschad_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spl_wisdm = pd.read_csv(\"../data/features/spl_wisdm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>coef_0_x</th>\n",
       "      <th>coef_1_x</th>\n",
       "      <th>coef_2_x</th>\n",
       "      <th>coef_3_x</th>\n",
       "      <th>coef_4_x</th>\n",
       "      <th>coef_5_x</th>\n",
       "      <th>coef_6_x</th>\n",
       "      <th>coef_7_x</th>\n",
       "      <th>coef_8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>coef_40_z</th>\n",
       "      <th>coef_41_z</th>\n",
       "      <th>coef_42_z</th>\n",
       "      <th>coef_43_z</th>\n",
       "      <th>coef_44_z</th>\n",
       "      <th>coef_45_z</th>\n",
       "      <th>coef_46_z</th>\n",
       "      <th>coef_47_z</th>\n",
       "      <th>coef_48_z</th>\n",
       "      <th>coef_49_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.845102</td>\n",
       "      <td>-2.852912</td>\n",
       "      <td>9.180071</td>\n",
       "      <td>-1.401187</td>\n",
       "      <td>11.738030</td>\n",
       "      <td>-2.519118</td>\n",
       "      <td>6.574491</td>\n",
       "      <td>-4.031136</td>\n",
       "      <td>17.467649</td>\n",
       "      <td>...</td>\n",
       "      <td>3.589595</td>\n",
       "      <td>-3.117073</td>\n",
       "      <td>-1.235503</td>\n",
       "      <td>2.469804</td>\n",
       "      <td>-4.359638</td>\n",
       "      <td>-1.306580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.094670</td>\n",
       "      <td>14.439397</td>\n",
       "      <td>-2.141248</td>\n",
       "      <td>3.832860</td>\n",
       "      <td>3.776352</td>\n",
       "      <td>-0.980070</td>\n",
       "      <td>13.237937</td>\n",
       "      <td>1.720668</td>\n",
       "      <td>-1.356833</td>\n",
       "      <td>...</td>\n",
       "      <td>3.857017</td>\n",
       "      <td>-3.336601</td>\n",
       "      <td>-0.896229</td>\n",
       "      <td>5.927022</td>\n",
       "      <td>-0.505250</td>\n",
       "      <td>-6.617887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.436514</td>\n",
       "      <td>5.276655</td>\n",
       "      <td>9.185416</td>\n",
       "      <td>-0.509384</td>\n",
       "      <td>0.480894</td>\n",
       "      <td>11.206549</td>\n",
       "      <td>-1.580749</td>\n",
       "      <td>4.972559</td>\n",
       "      <td>-1.647947</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.265185</td>\n",
       "      <td>-0.292136</td>\n",
       "      <td>2.400569</td>\n",
       "      <td>-8.215157</td>\n",
       "      <td>7.105995</td>\n",
       "      <td>-3.799797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.996452</td>\n",
       "      <td>15.720589</td>\n",
       "      <td>-3.774008</td>\n",
       "      <td>5.366599</td>\n",
       "      <td>-3.722388</td>\n",
       "      <td>14.630739</td>\n",
       "      <td>-2.882463</td>\n",
       "      <td>3.645236</td>\n",
       "      <td>0.057240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>-1.874479</td>\n",
       "      <td>1.041068</td>\n",
       "      <td>-1.949780</td>\n",
       "      <td>0.403705</td>\n",
       "      <td>-3.741833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.107837</td>\n",
       "      <td>14.744332</td>\n",
       "      <td>-5.974299</td>\n",
       "      <td>5.787027</td>\n",
       "      <td>-3.764102</td>\n",
       "      <td>11.344725</td>\n",
       "      <td>3.187560</td>\n",
       "      <td>-1.799950</td>\n",
       "      <td>4.777890</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.546385</td>\n",
       "      <td>3.404281</td>\n",
       "      <td>-0.832806</td>\n",
       "      <td>-3.615928</td>\n",
       "      <td>1.860831</td>\n",
       "      <td>-0.302996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  coef_0_x   coef_1_x  coef_2_x  coef_3_x   coef_4_x   coef_5_x  \\\n",
       "0         1  2.845102  -2.852912  9.180071 -1.401187  11.738030  -2.519118   \n",
       "1         1  3.094670  14.439397 -2.141248  3.832860   3.776352  -0.980070   \n",
       "2         1  1.436514   5.276655  9.185416 -0.509384   0.480894  11.206549   \n",
       "3         1 -1.996452  15.720589 -3.774008  5.366599  -3.722388  14.630739   \n",
       "4         1  1.107837  14.744332 -5.974299  5.787027  -3.764102  11.344725   \n",
       "\n",
       "    coef_6_x  coef_7_x   coef_8_x    ...      coef_40_z  coef_41_z  coef_42_z  \\\n",
       "0   6.574491 -4.031136  17.467649    ...       3.589595  -3.117073  -1.235503   \n",
       "1  13.237937  1.720668  -1.356833    ...       3.857017  -3.336601  -0.896229   \n",
       "2  -1.580749  4.972559  -1.647947    ...      -2.265185  -0.292136   2.400569   \n",
       "3  -2.882463  3.645236   0.057240    ...       0.387069  -1.874479   1.041068   \n",
       "4   3.187560 -1.799950   4.777890    ...      -5.546385   3.404281  -0.832806   \n",
       "\n",
       "   coef_43_z  coef_44_z  coef_45_z  coef_46_z  coef_47_z  coef_48_z  coef_49_z  \n",
       "0   2.469804  -4.359638  -1.306580        0.0        0.0        0.0        0.0  \n",
       "1   5.927022  -0.505250  -6.617887        0.0        0.0        0.0        0.0  \n",
       "2  -8.215157   7.105995  -3.799797        0.0        0.0        0.0        0.0  \n",
       "3  -1.949780   0.403705  -3.741833        0.0        0.0        0.0        0.0  \n",
       "4  -3.615928   1.860831  -0.302996        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl_wisdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
